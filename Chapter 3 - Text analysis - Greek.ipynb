{
 "metadata": {
  "name": "",
  "signature": "sha256:6dadb2f782a13b8d89045fdd8752187feac69feac31133f33af88fb037b70a98"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 3: Text Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-- *A Python Course for the Humanities by Folgert Karsdorp and Maarten van Gompel*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this chapter we will introduce you to the task of text analysis in Python. You will learn how to read an entire corpus into Python, clean it and how to perform certain data analyses on those texts. We will also briefly introduce you to using Python's plotting library *matplotlib*, with which you can visualize your data.\n",
      "\n",
      "Before we delve into the main subject of this chapter, text analysis, we will first write a couple of utility functions that build upon the things you learnt in the previous chapter. Often we don't work with a single text file stored at our computer, but with multiple text files or entire corpora. We would like to have a way to load a corpus into Python.\n",
      "\n",
      "Remember how to read files? Each time we had to open a file, read the contents and then close the file. Since this is a series of steps we will often need to do, we can write a single function that does all that for us. We write a small utility function `read_file(filename)` that reads the specified file and simply returns all contents as a single string."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_file(filename):\n",
      "    \"Read the contents of FILENAME and return as a string.\"\n",
      "    infile = open(filename) # windows users should add the encoding='utf-8' option\n",
      "    contents = infile.read()\n",
      "    infile.close()\n",
      "    return contents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, instead of having to open a file, read the contents and close the file, we can just call the function `read_file` to do all that:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = read_file(\"data/romans_1:14-23_gk.txt\")\n",
      "print(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \u1f1d\u03bb\u03bb\u03b7\u03c3\u03af\u03bd \u03c4\u03b5 \u03ba\u03b1\u1f76 \u03b2\u03b1\u03c1\u03b2\u03ac\u03c1\u03bf\u03b9\u03c2, \u03c3\u03bf\u03c6\u03bf\u1fd6\u03c2 \u03c4\u03b5 \u03ba\u03b1\u1f76 \u1f00\u03bd\u03bf\u03ae\u03c4\u03bf\u03b9\u03c2 \u1f40\u03c6\u03b5\u03b9\u03bb\u03ad\u03c4\u03b7\u03c2 \u03b5\u1f30\u03bc\u03af\u00b7 \u03bf\u1f55\u03c4\u03c9\u03c2 \u03c4\u1f78 \u03ba\u03b1\u03c4\u2019 \u1f10\u03bc\u1f72 \u03c0\u03c1\u03cc\u03b8\u03c5\u03bc\u03bf\u03bd \u03ba\u03b1\u1f76 \u1f51\u03bc\u1fd6\u03bd \u03c4\u03bf\u1fd6\u03c2 \u1f10\u03bd \u1fec\u03ce\u03bc\u1fc3 \u03b5\u1f50\u03b1\u03b3\u03b3\u03b5\u03bb\u03af\u03c3\u03b1\u03c3\u03b8\u03b1\u03b9. \u039f\u1f50 \u03b3\u1f70\u03c1 \u1f10\u03c0\u03b1\u03b9\u03c3\u03c7\u03cd\u03bd\u03bf\u03bc\u03b1\u03b9 \u03c4\u1f78 \u2e00\u03b5\u1f50\u03b1\u03b3\u03b3\u03ad\u03bb\u03b9\u03bf\u03bd, \u03b4\u03cd\u03bd\u03b1\u03bc\u03b9\u03c2 \u03b3\u1f70\u03c1 \u03b8\u03b5\u03bf\u1fe6 \u1f10\u03c3\u03c4\u03b9\u03bd \u03b5\u1f30\u03c2 \u03c3\u03c9\u03c4\u03b7\u03c1\u03af\u03b1\u03bd \u03c0\u03b1\u03bd\u03c4\u1f76 \u03c4\u1ff7 \u03c0\u03b9\u03c3\u03c4\u03b5\u03cd\u03bf\u03bd\u03c4\u03b9, \u1f38\u03bf\u03c5\u03b4\u03b1\u03af\u1ff3 \u03c4\u03b5 \u03c0\u03c1\u1ff6\u03c4\u03bf\u03bd \u03ba\u03b1\u1f76 \u1f1d\u03bb\u03bb\u03b7\u03bd\u03b9\u00b7 \u03b4\u03b9\u03ba\u03b1\u03b9\u03bf\u03c3\u03cd\u03bd\u03b7 \u03b3\u1f70\u03c1 \u03b8\u03b5\u03bf\u1fe6 \u1f10\u03bd \u03b1\u1f50\u03c4\u1ff7 \u1f00\u03c0\u03bf\u03ba\u03b1\u03bb\u03cd\u03c0\u03c4\u03b5\u03c4\u03b1\u03b9 \u1f10\u03ba \u03c0\u03af\u03c3\u03c4\u03b5\u03c9\u03c2 \u03b5\u1f30\u03c2 \u03c0\u03af\u03c3\u03c4\u03b9\u03bd, \u03ba\u03b1\u03b8\u1f7c\u03c2 \u03b3\u03ad\u03b3\u03c1\u03b1\u03c0\u03c4\u03b1\u03b9\u00b7 \u1f49 \u03b4\u1f72 \u03b4\u03af\u03ba\u03b1\u03b9\u03bf\u03c2 \u1f10\u03ba \u03c0\u03af\u03c3\u03c4\u03b5\u03c9\u03c2 \u03b6\u03ae\u03c3\u03b5\u03c4\u03b1\u03b9. \u1f08\u03c0\u03bf\u03ba\u03b1\u03bb\u03cd\u03c0\u03c4\u03b5\u03c4\u03b1\u03b9 \u03b3\u1f70\u03c1 \u1f40\u03c1\u03b3\u1f74 \u03b8\u03b5\u03bf\u1fe6 \u1f00\u03c0\u2019 \u03bf\u1f50\u03c1\u03b1\u03bd\u03bf\u1fe6 \u1f10\u03c0\u1f76 \u03c0\u1fb6\u03c3\u03b1\u03bd \u1f00\u03c3\u03ad\u03b2\u03b5\u03b9\u03b1\u03bd \u03ba\u03b1\u1f76 \u1f00\u03b4\u03b9\u03ba\u03af\u03b1\u03bd \u1f00\u03bd\u03b8\u03c1\u03ce\u03c0\u03c9\u03bd \u03c4\u1ff6\u03bd \u03c4\u1f74\u03bd \u1f00\u03bb\u03ae\u03b8\u03b5\u03b9\u03b1\u03bd \u1f10\u03bd \u1f00\u03b4\u03b9\u03ba\u03af\u1fb3 \u03ba\u03b1\u03c4\u03b5\u03c7\u03cc\u03bd\u03c4\u03c9\u03bd, \u03b4\u03b9\u03cc\u03c4\u03b9 \u03c4\u1f78 \u03b3\u03bd\u03c9\u03c3\u03c4\u1f78\u03bd \u03c4\u03bf\u1fe6 \u03b8\u03b5\u03bf\u1fe6 \u03c6\u03b1\u03bd\u03b5\u03c1\u03cc\u03bd \u1f10\u03c3\u03c4\u03b9\u03bd \u1f10\u03bd \u03b1\u1f50\u03c4\u03bf\u1fd6\u03c2, \u1f41 \u2e02\u03b8\u03b5\u1f78\u03c2 \u03b3\u1f70\u03c1\u2e03 \u03b1\u1f50\u03c4\u03bf\u1fd6\u03c2 \u1f10\u03c6\u03b1\u03bd\u03ad\u03c1\u03c9\u03c3\u03b5\u03bd. \u03c4\u1f70 \u03b3\u1f70\u03c1 \u1f00\u03cc\u03c1\u03b1\u03c4\u03b1 \u03b1\u1f50\u03c4\u03bf\u1fe6 \u1f00\u03c0\u1f78 \u03ba\u03c4\u03af\u03c3\u03b5\u03c9\u03c2 \u03ba\u03cc\u03c3\u03bc\u03bf\u03c5 \u03c4\u03bf\u1fd6\u03c2 \u03c0\u03bf\u03b9\u03ae\u03bc\u03b1\u03c3\u03b9\u03bd \u03bd\u03bf\u03bf\u03cd\u03bc\u03b5\u03bd\u03b1 \u03ba\u03b1\u03b8\u03bf\u03c1\u1fb6\u03c4\u03b1\u03b9, \u1f25 \u03c4\u03b5 \u1f00\u0390\u03b4\u03b9\u03bf\u03c2 \u03b1\u1f50\u03c4\u03bf\u1fe6 \u03b4\u03cd\u03bd\u03b1\u03bc\u03b9\u03c2 \u03ba\u03b1\u1f76 \u03b8\u03b5\u03b9\u03cc\u03c4\u03b7\u03c2, \u03b5\u1f30\u03c2 \u03c4\u1f78 \u03b5\u1f36\u03bd\u03b1\u03b9 \u03b1\u1f50\u03c4\u03bf\u1f7a\u03c2 \u1f00\u03bd\u03b1\u03c0\u03bf\u03bb\u03bf\u03b3\u03ae\u03c4\u03bf\u03c5\u03c2, \u03b4\u03b9\u03cc\u03c4\u03b9 \u03b3\u03bd\u03cc\u03bd\u03c4\u03b5\u03c2 \u03c4\u1f78\u03bd \u03b8\u03b5\u1f78\u03bd \u03bf\u1f50\u03c7 \u1f61\u03c2 \u03b8\u03b5\u1f78\u03bd \u1f10\u03b4\u03cc\u03be\u03b1\u03c3\u03b1\u03bd \u1f22 \u03b7\u1f50\u03c7\u03b1\u03c1\u03af\u03c3\u03c4\u03b7\u03c3\u03b1\u03bd, \u1f00\u03bb\u03bb\u1f70 \u1f10\u03bc\u03b1\u03c4\u03b1\u03b9\u03ce\u03b8\u03b7\u03c3\u03b1\u03bd \u1f10\u03bd \u03c4\u03bf\u1fd6\u03c2 \u03b4\u03b9\u03b1\u03bb\u03bf\u03b3\u03b9\u03c3\u03bc\u03bf\u1fd6\u03c2 \u03b1\u1f50\u03c4\u1ff6\u03bd \u03ba\u03b1\u1f76 \u1f10\u03c3\u03ba\u03bf\u03c4\u03af\u03c3\u03b8\u03b7 \u1f21 \u1f00\u03c3\u03cd\u03bd\u03b5\u03c4\u03bf\u03c2 \u03b1\u1f50\u03c4\u1ff6\u03bd \u03ba\u03b1\u03c1\u03b4\u03af\u03b1\u00b7 \u03c6\u03ac\u03c3\u03ba\u03bf\u03bd\u03c4\u03b5\u03c2 \u03b5\u1f36\u03bd\u03b1\u03b9 \u03c3\u03bf\u03c6\u03bf\u1f76 \u1f10\u03bc\u03c9\u03c1\u03ac\u03bd\u03b8\u03b7\u03c3\u03b1\u03bd, \u03ba\u03b1\u1f76 \u1f24\u03bb\u03bb\u03b1\u03be\u03b1\u03bd \u03c4\u1f74\u03bd \u03b4\u03cc\u03be\u03b1\u03bd \u03c4\u03bf\u1fe6 \u1f00\u03c6\u03b8\u03ac\u03c1\u03c4\u03bf\u03c5 \u03b8\u03b5\u03bf\u1fe6 \u1f10\u03bd \u1f41\u03bc\u03bf\u03b9\u03ce\u03bc\u03b1\u03c4\u03b9 \u03b5\u1f30\u03ba\u03cc\u03bd\u03bf\u03c2 \u03c6\u03b8\u03b1\u03c1\u03c4\u03bf\u1fe6 \u1f00\u03bd\u03b8\u03c1\u03ce\u03c0\u03bf\u03c5 \u03ba\u03b1\u1f76 \u03c0\u03b5\u03c4\u03b5\u03b9\u03bd\u1ff6\u03bd \u03ba\u03b1\u1f76 \u03c4\u03b5\u03c4\u03c1\u03b1\u03c0\u03cc\u03b4\u03c9\u03bd \u03ba\u03b1\u1f76 \u1f11\u03c1\u03c0\u03b5\u03c4\u1ff6\u03bd.\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the directory `data/NT/Raw` we have a corpus consisting of multiple files with the extension `.txt`. This corpus contains all the books of the New Testament in the raw text format from https://github.com/morphgnt/sblgnt. We want to iterate over all these files. You can do this using the `listdir` function from the `os` module. We import this function as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After that, the `listdir` function is available to use. This function takes as argument the path to a directory and returns all the files and subdirectories present in that directory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "listdir(\"data\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "['NT',\n",
        " 'names',\n",
        " 'romans_gk.txt',\n",
        " 'romans_1:14-23_gk.txt',\n",
        " 'romans-frequency-distribution.txt',\n",
        " 'romans_1_gk.txt',\n",
        " 'romans_greeting_gk.txt',\n",
        " 'austen-emma-excerpt.txt',\n",
        " 'british-novels',\n",
        " 'arabian_nights',\n",
        " 'austen-emma.txt',\n",
        " 'twitter.txt',\n",
        " 'gutenberg',\n",
        " 'austen-emma-excerpt-tokenised.txt',\n",
        " 'haggard',\n",
        " 'romans_punc.txt']"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that `listdir` returns a list and we can iterate over that list. Now, consider the following function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_textfiles(directory):\n",
      "    \"Return a list of filenames ending in '.txt' in DIRECTORY.\"\n",
      "    textfiles = []\n",
      "    for filename in listdir(directory):\n",
      "        if filename.endswith(\".txt\"):\n",
      "            textfiles.append(directory + \"/\" + filename)\n",
      "    return textfiles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `listdir` takes as argument the name of a directory and lists all filenames in that directory. We iterate over this list and append each filename that ends with the extension, `.txt` to a new list of `textfiles`. Using the `list_textfiles` function, the following code will read all text files in the directory `data/NT/Raw` and outputs the length (in characters) of each:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for filepath in list_textfiles(\"data/NT/Raw\"):\n",
      "    text = read_file(filepath)\n",
      "    print(filepath +  \" has \" + str(len(text)) + \" characters.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data/NT/Raw/80-Jas-morphgnt.txt has 74786 characters.\n",
        "data/NT/Raw/72-Col-morphgnt.txt has 67095 characters.\n",
        "data/NT/Raw/77-Tit-morphgnt.txt has 29830 characters.\n",
        "data/NT/Raw/78-Phm-morphgnt.txt has 13876 characters.\n",
        "data/NT/Raw/76-2Ti-morphgnt.txt has 54222 characters.\n",
        "data/NT/Raw/62-Mk-morphgnt.txt has 483360 characters.\n",
        "data/NT/Raw/73-1Th-morphgnt.txt has 62672 characters.\n",
        "data/NT/Raw/66-Ro-morphgnt.txt has 296672 characters.\n",
        "data/NT/Raw/75-1Ti-morphgnt.txt has 71475 characters.\n",
        "data/NT/Raw/81-1Pe-morphgnt.txt has 73917 characters.\n",
        "data/NT/Raw/67-1Co-morphgnt.txt has 285774 characters.\n",
        "data/NT/Raw/61-Mt-morphgnt.txt has 776472 characters.\n",
        "data/NT/Raw/86-Jud-morphgnt.txt has 20568 characters.\n",
        "data/NT/Raw/64-Jn-morphgnt.txt has 634935 characters.\n",
        "data/NT/Raw/63-Lk-morphgnt.txt has 826159 characters.\n",
        "data/NT/Raw/82-2Pe-morphgnt.txt has 48947 characters.\n",
        "data/NT/Raw/84-2Jn-morphgnt.txt has 10083 characters.\n",
        "data/NT/Raw/87-Re-morphgnt.txt has 406511 characters.\n",
        "data/NT/Raw/65-Ac-morphgnt.txt has 798555 characters.\n",
        "data/NT/Raw/69-Ga-morphgnt.txt has 94865 characters.\n",
        "data/NT/Raw/71-Php-morphgnt.txt has 68869 characters.\n",
        "data/NT/Raw/70-Eph-morphgnt.txt has 102301 characters.\n",
        "data/NT/Raw/74-2Th-morphgnt.txt has 34672 characters.\n",
        "data/NT/Raw/79-Heb-morphgnt.txt has 216462 characters.\n",
        "data/NT/Raw/85-3Jn-morphgnt.txt has 9408 characters.\n",
        "data/NT/Raw/68-2Co-morphgnt.txt has 190249 characters.\n",
        "data/NT/Raw/83-1Jn-morphgnt.txt has 86315 characters.\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "General Text Statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> \u1f10\u03ac\u03bd \u03c4\u03b9\u03c2 \u1f10\u03c0\u03b9\u03b8\u1fc7 \u1f10\u03c0\u2019 \u03b1\u1f50\u03c4\u03ac, \u1f10\u03c0\u03b9\u03b8\u03ae\u03c3\u03b5\u03b9 \u1f41 \u03b8\u03b5\u1f78\u03c2 \u1f10\u03c0\u2019 \u03b1\u1f50\u03c4\u1f78\u03bd \u03c4\u1f70\u03c2 \u03c0\u03bb\u03b7\u03b3\u1f70\u03c2 \u03c4\u1f70\u03c2 \u03b3\u03b5\u03b3\u03c1\u03b1\u03bc\u03bc\u03ad\u03bd\u03b1\u03c2 \u1f10\u03bd \u03c4\u1ff7 \u03b2\u03b9\u03b2\u03bb\u03af\u1ff3 \u03c4\u03bf\u03cd\u03c4\u1ff3\u00b7"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the great advantages of being a student of the Bible in the digital age is the great amount of information that is available, one might even say that has been _added_, to the plain text of the Bible.  Besides the innumerable amateur, professional, and semi-professional commentaries on words, passages, and whole books, there are also many very useful sites that contain more information about the very words themselves, whether this information is lexical, syntactic, or textual.  Besides well-known sites such as <a href='http://www.perseus.tufts.edu/hopper/'>Perseus</a> or the German Bible Society's <a href='http://www.academic-bible.com/en/home/'>Academic Bible Portal</a>, there are also older or lesser known projects, like the <a href='http://ccat.sas.upenn.edu/rak/catss.html'>Computer Assisted Tools for Septuagint/Scriptural Study</a>.\n",
      "\n",
      "The texts that we are going to work with for the rest of this lesson come from a very current project to analyze every word in the New Testament, the <a href='http://morphgnt.org/'>MorphGNT</a> project, which provides \"linguistic databases and Python tools for the Greek New Testament.\"  (If you're interested in the Hebrew Bible, check out <a href='https://github.com/openscriptures/morphhb'>MorphHB</a>.)  If we take a look at one line of one of their files, we will see what a wealth of information they have.\n",
      "\n",
      "> 010405 V- 3AAI-S-- \u2e00\u1f14\u03c3\u03c4\u03b7\u03c3\u03b5\u03bd \u1f14\u03c3\u03c4\u03b7\u03c3\u03b5\u03bd \u1f14\u03c3\u03c4\u03b7\u03c3\u03b5(\u03bd) \u1f35\u03c3\u03c4\u03b7\u03bc\u03b9\n",
      "\n",
      "As you can see, each line is divided by spaces into 7 parts.  The first part, the six digits, consists of three 2-digit groups that tell us the book, chapter and verse in which this word occurs, in this case Matthew (book 01) 4:5.  The second part represents the part of speech, here a verb.  The next part is an 8-part parsing code.  This one tells us that the verb is a `3`rd person `A`orist `A`ctive `I`ndicative `S`ingular verb form.  The final four parts represent the text of the word in different states: 1) exactly as it appears in the text, 2) without punctuation, 3) normalized, and 4) lemma.  And every word in the New Testament is represented by such a line.  Perhaps you can imagine some of the possibilities!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to recreate the biblical text of the SBLGNT, the text used by MorphGNT.  We could use the `read_file` function above but, as we just saw, the MorphGNT files are not set up as a running text but, instead, as lines that each represent a single word.  So the first thing we should do is to rewrite this function to split a text file into lines instead of reading it in as one string, as we did above.  Take a look at our new function below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_file_lines(filename):\n",
      "    infile = open(filename) # windows users should add the encoding='utf-8' option\n",
      "    contents = infile.read()\n",
      "    infile.close()\n",
      "    contents = contents.split('\\n') # \\n is the line separator\n",
      "    return contents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The only difference between the two functions (besides the name) is that we have added the line\n",
      "\n",
      "    contents = contents.split('\\n')\n",
      "    \n",
      "If we pass the string `'\\n'` to the `split` method, it will split the string on the line separator '\\n' and return a list where each member is a separate line in the original file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = read_file_lines('data/NT/Raw/85-3Jn-morphgnt.txt')\n",
      "lines[:5]\n",
      "type(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "list"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our list `lines` now has the information for every word in 3 John separated into one line per word.  Your task is to write code below that will loop through each line of the `lines` list, extract the word as it appears in the text from each line, and add that word to a string object (called `Third_Jn`) that will then be the whole text of 3 John as it appears in the SLBGNT."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Third_Jn = ''\n",
      "print(lines[0].split())\n",
      "# insert your code here\n",
      "for line in lines:\n",
      "    this_line = line.split()\n",
      "    Third_Jn += this_line[3] + ' '\n",
      "Third_Jn = Third_Jn.strip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['250101', 'RA', '----NSM-', '\u1f49', '\u1f49', '\u1f41', '\u1f41']\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have the whole book 3 John in the string variable `Third_Jn`.  Let's see how it looks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Third_Jn)\n",
      "type(Third_Jn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u1f49 \u03c0\u03c1\u03b5\u03c3\u03b2\u03cd\u03c4\u03b5\u03c1\u03bf\u03c2 \u0393\u03b1\u0390\u1ff3 \u03c4\u1ff7 \u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u1ff7, \u1f43\u03bd \u1f10\u03b3\u1f7c \u1f00\u03b3\u03b1\u03c0\u1ff6 \u1f10\u03bd \u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3. \u1f08\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad, \u03c0\u03b5\u03c1\u1f76 \u03c0\u03ac\u03bd\u03c4\u03c9\u03bd \u03b5\u1f54\u03c7\u03bf\u03bc\u03b1\u03af \u03c3\u03b5 \u03b5\u1f50\u03bf\u03b4\u03bf\u1fe6\u03c3\u03b8\u03b1\u03b9 \u03ba\u03b1\u1f76 \u1f51\u03b3\u03b9\u03b1\u03af\u03bd\u03b5\u03b9\u03bd, \u03ba\u03b1\u03b8\u1f7c\u03c2 \u03b5\u1f50\u03bf\u03b4\u03bf\u1fe6\u03c4\u03b1\u03af \u03c3\u03bf\u03c5 \u1f21 \u03c8\u03c5\u03c7\u03ae. \u1f10\u03c7\u03ac\u03c1\u03b7\u03bd \u03b3\u1f70\u03c1 \u03bb\u03af\u03b1\u03bd \u1f10\u03c1\u03c7\u03bf\u03bc\u03ad\u03bd\u03c9\u03bd \u1f00\u03b4\u03b5\u03bb\u03c6\u1ff6\u03bd \u03ba\u03b1\u1f76 \u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03bf\u03cd\u03bd\u03c4\u03c9\u03bd \u03c3\u03bf\u03c5 \u03c4\u1fc7 \u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3, \u03ba\u03b1\u03b8\u1f7c\u03c2 \u03c3\u1f7a \u1f10\u03bd \u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3 \u03c0\u03b5\u03c1\u03b9\u03c0\u03b1\u03c4\u03b5\u1fd6\u03c2. \u03bc\u03b5\u03b9\u03b6\u03bf\u03c4\u03ad\u03c1\u03b1\u03bd \u03c4\u03bf\u03cd\u03c4\u03c9\u03bd \u03bf\u1f50\u03ba \u1f14\u03c7\u03c9 \u2e00\u03c7\u03b1\u03c1\u03ac\u03bd, \u1f35\u03bd\u03b1 \u1f00\u03ba\u03bf\u03cd\u03c9 \u03c4\u1f70 \u1f10\u03bc\u1f70 \u03c4\u03ad\u03ba\u03bd\u03b1 \u1f10\u03bd \u2e00\u03c4\u1fc7 \u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3 \u03c0\u03b5\u03c1\u03b9\u03c0\u03b1\u03c4\u03bf\u1fe6\u03bd\u03c4\u03b1. \u1f08\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad, \u03c0\u03b9\u03c3\u03c4\u1f78\u03bd \u03c0\u03bf\u03b9\u03b5\u1fd6\u03c2 \u1f43 \u1f10\u1f70\u03bd \u1f10\u03c1\u03b3\u03ac\u03c3\u1fc3 \u03b5\u1f30\u03c2 \u03c4\u03bf\u1f7a\u03c2 \u1f00\u03b4\u03b5\u03bb\u03c6\u03bf\u1f7a\u03c2 \u03ba\u03b1\u1f76 \u2e00\u03c4\u03bf\u1fe6\u03c4\u03bf \u03be\u03ad\u03bd\u03bf\u03c5\u03c2, \u03bf\u1f33 \u1f10\u03bc\u03b1\u03c1\u03c4\u03cd\u03c1\u03b7\u03c3\u03ac\u03bd \u03c3\u03bf\u03c5 \u03c4\u1fc7 \u1f00\u03b3\u03ac\u03c0\u1fc3 \u1f10\u03bd\u03ce\u03c0\u03b9\u03bf\u03bd \u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1\u03c2, \u03bf\u1f53\u03c2 \u03ba\u03b1\u03bb\u1ff6\u03c2 \u03c0\u03bf\u03b9\u03ae\u03c3\u03b5\u03b9\u03c2 \u03c0\u03c1\u03bf\u03c0\u03ad\u03bc\u03c8\u03b1\u03c2 \u1f00\u03be\u03af\u03c9\u03c2 \u03c4\u03bf\u1fe6 \u03b8\u03b5\u03bf\u1fe6\u00b7 \u1f51\u03c0\u1f72\u03c1 \u03b3\u1f70\u03c1 \u03c4\u03bf\u1fe6 \u1f40\u03bd\u03cc\u03bc\u03b1\u03c4\u03bf\u03c2 \u1f10\u03be\u1fc6\u03bb\u03b8\u03bf\u03bd \u03bc\u03b7\u03b4\u1f72\u03bd \u03bb\u03b1\u03bc\u03b2\u03ac\u03bd\u03bf\u03bd\u03c4\u03b5\u03c2 \u1f00\u03c0\u1f78 \u03c4\u1ff6\u03bd \u2e00\u1f10\u03b8\u03bd\u03b9\u03ba\u1ff6\u03bd. \u1f21\u03bc\u03b5\u1fd6\u03c2 \u03bf\u1f56\u03bd \u1f40\u03c6\u03b5\u03af\u03bb\u03bf\u03bc\u03b5\u03bd \u2e00\u1f51\u03c0\u03bf\u03bb\u03b1\u03bc\u03b2\u03ac\u03bd\u03b5\u03b9\u03bd \u03c4\u03bf\u1f7a\u03c2 \u03c4\u03bf\u03b9\u03bf\u03cd\u03c4\u03bf\u03c5\u03c2, \u1f35\u03bd\u03b1 \u03c3\u03c5\u03bd\u03b5\u03c1\u03b3\u03bf\u1f76 \u03b3\u03b9\u03bd\u03ce\u03bc\u03b5\u03b8\u03b1 \u03c4\u1fc7 \u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3. \u1f1c\u03b3\u03c1\u03b1\u03c8\u03ac \u2e00\u03c4\u03b9 \u03c4\u1fc7 \u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u1fb3\u00b7 \u1f00\u03bb\u03bb\u2019 \u1f41 \u03c6\u03b9\u03bb\u03bf\u03c0\u03c1\u03c9\u03c4\u03b5\u03cd\u03c9\u03bd \u03b1\u1f50\u03c4\u1ff6\u03bd \u0394\u03b9\u03bf\u03c4\u03c1\u03ad\u03c6\u03b7\u03c2 \u03bf\u1f50\u03ba \u1f10\u03c0\u03b9\u03b4\u03ad\u03c7\u03b5\u03c4\u03b1\u03b9 \u1f21\u03bc\u1fb6\u03c2. \u03b4\u03b9\u1f70 \u03c4\u03bf\u1fe6\u03c4\u03bf, \u1f10\u1f70\u03bd \u1f14\u03bb\u03b8\u03c9, \u1f51\u03c0\u03bf\u03bc\u03bd\u03ae\u03c3\u03c9 \u03b1\u1f50\u03c4\u03bf\u1fe6 \u03c4\u1f70 \u1f14\u03c1\u03b3\u03b1 \u1f03 \u03c0\u03bf\u03b9\u03b5\u1fd6, \u03bb\u03cc\u03b3\u03bf\u03b9\u03c2 \u03c0\u03bf\u03bd\u03b7\u03c1\u03bf\u1fd6\u03c2 \u03c6\u03bb\u03c5\u03b1\u03c1\u1ff6\u03bd \u1f21\u03bc\u1fb6\u03c2, \u03ba\u03b1\u1f76 \u03bc\u1f74 \u1f00\u03c1\u03ba\u03bf\u03cd\u03bc\u03b5\u03bd\u03bf\u03c2 \u1f10\u03c0\u1f76 \u03c4\u03bf\u03cd\u03c4\u03bf\u03b9\u03c2 \u03bf\u1f54\u03c4\u03b5 \u03b1\u1f50\u03c4\u1f78\u03c2 \u1f10\u03c0\u03b9\u03b4\u03ad\u03c7\u03b5\u03c4\u03b1\u03b9 \u03c4\u03bf\u1f7a\u03c2 \u1f00\u03b4\u03b5\u03bb\u03c6\u03bf\u1f7a\u03c2 \u03ba\u03b1\u1f76 \u03c4\u03bf\u1f7a\u03c2 \u03b2\u03bf\u03c5\u03bb\u03bf\u03bc\u03ad\u03bd\u03bf\u03c5\u03c2 \u03ba\u03c9\u03bb\u03cd\u03b5\u03b9 \u03ba\u03b1\u1f76 \u1f10\u03ba \u03c4\u1fc6\u03c2 \u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1\u03c2 \u1f10\u03ba\u03b2\u03ac\u03bb\u03bb\u03b5\u03b9. \u1f08\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad, \u03bc\u1f74 \u03bc\u03b9\u03bc\u03bf\u1fe6 \u03c4\u1f78 \u03ba\u03b1\u03ba\u1f78\u03bd \u1f00\u03bb\u03bb\u1f70 \u03c4\u1f78 \u1f00\u03b3\u03b1\u03b8\u03cc\u03bd. \u1f41 \u1f00\u03b3\u03b1\u03b8\u03bf\u03c0\u03bf\u03b9\u1ff6\u03bd \u1f10\u03ba \u03c4\u03bf\u1fe6 \u03b8\u03b5\u03bf\u1fe6 \u1f10\u03c3\u03c4\u03b9\u03bd\u00b7 \u1f41 \u03ba\u03b1\u03ba\u03bf\u03c0\u03bf\u03b9\u1ff6\u03bd \u03bf\u1f50\u03c7 \u1f11\u03ce\u03c1\u03b1\u03ba\u03b5\u03bd \u03c4\u1f78\u03bd \u03b8\u03b5\u03cc\u03bd. \u0394\u03b7\u03bc\u03b7\u03c4\u03c1\u03af\u1ff3 \u03bc\u03b5\u03bc\u03b1\u03c1\u03c4\u03cd\u03c1\u03b7\u03c4\u03b1\u03b9 \u1f51\u03c0\u1f78 \u03c0\u03ac\u03bd\u03c4\u03c9\u03bd \u03ba\u03b1\u1f76 \u1f51\u03c0\u1f78 \u03b1\u1f50\u03c4\u1fc6\u03c2 \u03c4\u1fc6\u03c2 \u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u03b1\u03c2\u00b7 \u03ba\u03b1\u1f76 \u1f21\u03bc\u03b5\u1fd6\u03c2 \u03b4\u1f72 \u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03bf\u1fe6\u03bc\u03b5\u03bd, \u03ba\u03b1\u1f76 \u2e00\u03bf\u1f36\u03b4\u03b1\u03c2 \u1f45\u03c4\u03b9 \u1f21 \u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03af\u03b1 \u1f21\u03bc\u1ff6\u03bd \u1f00\u03bb\u03b7\u03b8\u03ae\u03c2 \u1f10\u03c3\u03c4\u03b9\u03bd. \u03a0\u03bf\u03bb\u03bb\u1f70 \u03b5\u1f36\u03c7\u03bf\u03bd \u2e02\u03b3\u03c1\u03ac\u03c8\u03b1\u03b9 \u03c3\u03bf\u03b9\u2e03, \u1f00\u03bb\u03bb\u2019 \u03bf\u1f50 \u03b8\u03ad\u03bb\u03c9 \u03b4\u03b9\u1f70 \u03bc\u03ad\u03bb\u03b1\u03bd\u03bf\u03c2 \u03ba\u03b1\u1f76 \u03ba\u03b1\u03bb\u03ac\u03bc\u03bf\u03c5 \u03c3\u03bf\u03b9 \u2e00\u03b3\u03c1\u03ac\u03c6\u03b5\u03b9\u03bd\u00b7 \u1f10\u03bb\u03c0\u03af\u03b6\u03c9 \u03b4\u1f72 \u03b5\u1f50\u03b8\u03ad\u03c9\u03c2 \u2e02\u03c3\u03b5 \u1f30\u03b4\u03b5\u1fd6\u03bd\u2e03, \u03ba\u03b1\u1f76 \u03c3\u03c4\u03cc\u03bc\u03b1 \u03c0\u03c1\u1f78\u03c2 \u03c3\u03c4\u03cc\u03bc\u03b1 \u03bb\u03b1\u03bb\u03ae\u03c3\u03bf\u03bc\u03b5\u03bd. \u0395\u1f30\u03c1\u03ae\u03bd\u03b7 \u03c3\u03bf\u03b9. \u1f00\u03c3\u03c0\u03ac\u03b6\u03bf\u03bd\u03c4\u03b1\u03af \u03c3\u03b5 \u03bf\u1f31 \u03c6\u03af\u03bb\u03bf\u03b9. \u1f00\u03c3\u03c0\u03ac\u03b6\u03bf\u03c5 \u03c4\u03bf\u1f7a\u03c2 \u03c6\u03af\u03bb\u03bf\u03c5\u03c2 \u03ba\u03b1\u03c4\u2019 \u1f44\u03bd\u03bf\u03bc\u03b1.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "str"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How does it look?  If you see any problems, go back to your code and correct them.  Now that we have the text of the book, it would be a shame to lose it.  We could recreate it easily, but we could just save it to a text file and wouldn't need to.  Plus, saving it will allow us to use the .txt file with other programs on our system.\n",
      "\n",
      "But before we just blunder into giving the file any name we want, let's take a look at how the files from MorphGNT are named."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_textfiles(\"data/NT/Raw\")[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "['data/NT/Raw/80-Jas-morphgnt.txt',\n",
        " 'data/NT/Raw/72-Col-morphgnt.txt',\n",
        " 'data/NT/Raw/77-Tit-morphgnt.txt',\n",
        " 'data/NT/Raw/78-Phm-morphgnt.txt',\n",
        " 'data/NT/Raw/76-2Ti-morphgnt.txt',\n",
        " 'data/NT/Raw/62-Mk-morphgnt.txt',\n",
        " 'data/NT/Raw/73-1Th-morphgnt.txt',\n",
        " 'data/NT/Raw/66-Ro-morphgnt.txt',\n",
        " 'data/NT/Raw/75-1Ti-morphgnt.txt',\n",
        " 'data/NT/Raw/81-1Pe-morphgnt.txt']"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, the files are sorted in the order in which they appear in the NT by the number that begins their file name (61, 62, 63, etc.).  It would be a shame to lose this information, so we would like to keep this number at the beginning of all of the files.  We could simply load each file and give each one its own name.  But we are learning to program to save ourselves the trouble of having to do such things.  So what we will do below is build a series of functions that will allow us to load each file, read its text into a string, and then save the string with a filename appropriate for that book of the Bible."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1)** We want to build our `save as` filenames using the original filenames as a guide.  To do this, the first thing we need to do is to remove the file extension from the filename, in our case `.txt`.  Write a function `remove_ext` that takes as argument a string. It should return the string without the file extension. Tip: use the function `splitext` from the `os.path` module. Look up the documentation [here](https://docs.python.org/3.4/library/os.path.html#os.path.splitext)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os.path import splitext\n",
      "\n",
      "def remove_ext(filename):\n",
      "    # insert your code here\n",
      "    return splitext(filename)[0]\n",
      "# these tests should return True if your code is correct\n",
      "print(remove_ext(\"data/NT/Raw/61-Mt-morphgnt.txt\") == \"data/NT/Raw/61-Mt-morphgnt\")\n",
      "print(remove_ext(\"ridiculous_selfie.jpg\") == \"ridiculous_selfie\")\n",
      "print(remove_ext(\"data/NT/Raw/61-Mt-morphgnt.txt\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True\n",
        "data/NT/Raw/61-Mt-morphgnt\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2)** Next, we need to remove the directory from the front of the filename.  Write a function `remove_dir` that takes as argument a filepath and removes the directory from a filepath. Tip: use the function `basename` from the `os.path` module. Look up the document [here](http://docs.python.org/3.4/library/os.path.html#os.path.basename)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os.path import basename\n",
      "\n",
      "def remove_dir(filepath):\n",
      "    # insert your code here\n",
      "    return basename(filepath)\n",
      "# these tests should return True if your code is correct\n",
      "print(remove_dir(\"data/NT/Raw/61-Mt-morphgnt.txt\") == \"61-Mt-morphgnt.txt\")\n",
      "print(remove_dir(\"/a/kind/of/funny/filepath/to/file.txt\") == \"file.txt\")\n",
      "print(remove_dir(\"data/NT/Raw/61-Mt-morphgnt.txt\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True\n",
        "61-Mt-morphgnt.txt\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3)** Combine the two functions `remove_ext` and `remove_dir` into one function `get_filename`. This function takes as argument a filepath and returns the name (without the extensions) of the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_filename(filepath):\n",
      "    # insert your code here\n",
      "    #return splitext(basename(filepath))[0]\n",
      "    return remove_ext(remove_dir(filepath))\n",
      "# these tests should return True if your code is correct\n",
      "print(get_filename(\"data/NT/Raw/61-Mt-morphgnt.txt\") == '61-Mt-morphgnt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The final step is to strip the part of the filename that we don't want in our `save as` filename, i.e., the '-morphgnt' part.  Below we will present two different ways to do this.  \n",
      "\n",
      "The first way is useful if you want to strip the same sequence of characters from the beginning or the end of the filename, or any string.  It takes advantage of the `strip`, `lstrip`, and `rstrip` methods on strings.  Let's take a look at how they work.\n",
      "\n",
      "As the names suggest, they 'strip' something from a string, either on both sides (`strip`), the left side (`lstrip`), or the right side (`rstrip`).  Take a look."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "string = '...wo.rd...'\n",
      "print(string.strip('.'))\n",
      "print(string.lstrip('.'))\n",
      "print(string.rstrip('.'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "wo.rd\n",
        "wo.rd...\n",
        "...wo.rd\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that it strips __all__ occurrences of the string from the left and/or right side.  Below, right a short bit of code using `strip` that gives us what we want."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name = '61-Mt-morphgnt'\n",
      "#insert your code here\n",
      "new_name = name.rstrip('-morphgnt').rstrip('-')\n",
      "print(new_name == '61-Mt')\n",
      "print(new_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "61-Mt\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Did you have any problems?  If so, why?\n",
      "\n",
      "The second method is a bit more generalizable and will not run into the problem we had above.  It uses the `split` method that we have already seen.  Try to figure out below how to use `split` in the function below to give us what we want."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name = '61-Mt-morphgnt'\n",
      "def build_filename(f_name):\n",
      "    #insert your code here\n",
      "    new_name = f_name.split('-')\n",
      "    new_name = new_name[0] + '-' + new_name[1] + '.txt'\n",
      "    return new_name\n",
      "print(build_filename(name) == '61-Mt.txt')\n",
      "print(build_filename(name))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "61-Mt.txt\n",
        "61-Mt\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not quite as easy but, trust me, knowing how to split and reconstitute filenames, and strings in general, will be of enormous use.  And now we have a function that will do it for us."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, finally, combine the functions `get_filename` and `build_filename` into the function `saveas_filename` to obtain the filename we want to use to save the resulting text."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveas_filename(filepath):\n",
      "    # insert your code here\n",
      "    #new_name = get_filename(filepath)\n",
      "    #new_name = build_filename(new_name)\n",
      "    return build_filename(get_filename(filepath))\n",
      "# these tests should return True if your code is correct\n",
      "print(saveas_filename(\"data/NT/Raw/61-Mt-morphgnt.txt\") == \"61-Mt.txt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, so we now have the tools we need read the text of every NT book into a file of its own.  The problem is that we are losing a lot of information when we do this.  What we want to do below is to construct a function that will capture some of this information for us: the chapter and verse numbers for the text.  And while we could simply insert these into the text at the correct place, instead we will use a dictionary to organize this information in a way that is easily retrievable later.\n",
      "\n",
      "We learned about dictionaries in Chapter 1.  Remember dictionaries are made up of key:value pairs that allow us to look up the values very easily: `dict(key)` will return the value of that key in the dictionary.  But the `values` in a dictionary do not have to be strings, integers, etc.  They can also be other Python objects, like lists or even other dictionaries!  Take a look."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = {}\n",
      "d['list'] = [1, 2, 3, 4, 5]\n",
      "d['dict'] = {'\u1f41': 'the', '\u03b8\u03b5\u03cc\u03c2': 'God'}\n",
      "d['Mt'] = {1: {1: ['\u03b2\u03af\u03b2\u03bb\u03bf\u03c2', '\u03b3\u03b5\u03bd\u03ad\u03c3\u03b5\u03c9\u03c2', '\u1f38\u03b7\u03c3\u03bf\u1fe6', '\u03a7\u03c1\u03b9\u03c3\u03c4\u03bf\u1fe6', '\u03c5\u1f31\u03bf\u1fe6', '\u0394\u03b1\u03c5\u1f76\u03b4', '\u03c5\u1f31\u03bf\u1fe6', '\u1f08\u03b2\u03c1\u03b1\u03ac\u03bc']}}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Do you see what is going on with `d['Mt']`?  This is what we want to end up with.  And look what we can do with it then."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(d['Mt'][1][1]) #print out the words in Matthew chapter 1, verse 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['\u03b2\u03af\u03b2\u03bb\u03bf\u03c2', '\u03b3\u03b5\u03bd\u03ad\u03c3\u03b5\u03c9\u03c2', '\u1f38\u03b7\u03c3\u03bf\u1fe6', '\u03a7\u03c1\u03b9\u03c3\u03c4\u03bf\u1fe6', '\u03c5\u1f31\u03bf\u1fe6', '\u0394\u03b1\u03c5\u1f76\u03b4', '\u03c5\u1f31\u03bf\u1fe6', '\u1f08\u03b2\u03c1\u03b1\u03ac\u03bc']\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This may appear to be a difficult task at first, but if we break it down into its component steps, we should be able to accomplish it without too much trouble.\n",
      "\n",
      "The best way to go about it is to build the dictionary from the inside out.  That is, first we will build the list of words in each verse, then put together each verse for each chapter, and then, finally, put together all the chapters in the book.  First, let's take another look at what the lines look like in the original files.\n",
      "\n",
      "> 010405 V- 3AAI-S-- \u2e00\u1f14\u03c3\u03c4\u03b7\u03c3\u03b5\u03bd \u1f14\u03c3\u03c4\u03b7\u03c3\u03b5\u03bd \u1f14\u03c3\u03c4\u03b7\u03c3\u03b5(\u03bd) \u1f35\u03c3\u03c4\u03b7\u03bc\u03b9\n",
      "\n",
      "Our first task will be to write a function that takes such a line as input and extracts the elements that we want, in this case the first element that represents the book, chapter, and verse for each word.  We have 4 different forms of the word to choose from.  For this activity, we'll use the normalized form of the word, i.e., the third word or the sixth element of each line.  The normalized form has capitalization normalized (NB, not always lowercased), punctuation removed, and accents normalized so that the same morphological form of the lemma will always appear in the same form.  This will make it easier to extract word statistics, as we saw above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bcv_word_extract(line):\n",
      "    #insert your code here\n",
      "    new = line.split()\n",
      "    return (new[0], new[5])\n",
      "print(bcv_word_extract('010405 V- 3AAI-S-- \u2e00\u1f14\u03c3\u03c4\u03b7\u03c3\u03b5\u03bd \u1f14\u03c3\u03c4\u03b7\u03c3\u03b5\u03bd \u1f14\u03c3\u03c4\u03b7\u03c3\u03b5(\u03bd) \u1f35\u03c3\u03c4\u03b7\u03bc\u03b9') == ('010405', '\u1f14\u03c3\u03c4\u03b7\u03c3\u03b5(\u03bd)'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now have the information that we need to build a list of words in each verse.  But how do we get this information into a dictionary?  Below we see the typical problem you will have with dictionaries."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verses = {} #initialize our dictionary\n",
      "for word in d['Mt'][1][1]: #loop through the list of words in Matthew 1:1\n",
      "    verses['010101'] = word\n",
      "print(verses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'010101': '\u1f08\u03b2\u03c1\u03b1\u03ac\u03bc'}\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that `verses['010101']` only has one word in it, the last one.  What we would like to have, instead, is a list of words.  But look at what happens when we try to do this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verses = {} #initialize our dictionary\n",
      "for word in d['Mt'][1][1]: #loop through the list of words in Matthew 1:1\n",
      "    verses['010101'].append(word)\n",
      "print(verses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'010101'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-48-06dbc2bf1f2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mverses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m#initialize our dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Mt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#loop through the list of words in Matthew 1:1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mverses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'010101'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: '010101'"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now what is the problem?  The problem is that the key `'010101'` does not exist in our dictionary.  We could write a function that checks to see if the key exists and creates it if it doesn't, but there is a simpler way to do this.\n",
      "\n",
      "The builtin `collections` library has an object called `defaultdict`.  We can use `defaultdict` to specify the default __function__ that `defaultdict` will use when it initializes a non-existent key.  Check out the syntax below"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "default_dict_1 = defaultdict(list)\n",
      "print(default_dict_1)\n",
      "print(default_dict_1['key_2'])\n",
      "default_dict_1['key_1'].append('value_1')\n",
      "print(default_dict_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<class 'list'>, {})\n",
        "[]\n",
        "defaultdict(<class 'list'>, {'key_2': [], 'key_1': ['value_1']})\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As I said above, the default value for a `defaultdict` must be a function, like `list`, `dict`, `int`, etc.  So, for instance, we cannot use `defaultdict` to do this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "default_dict_2 = defaultdict(int)\n",
      "print(default_dict_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<class 'int'>, {})\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Don't worry.  There are other ways to assign a default value to a dictionary.  Look at the Python <a href='https://docs.python.org/3/library/stdtypes.html?highlight=setdefault#dict.setdefault'>`dict.setdefault()` documentation</a> if you are interested in this."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, you should be able to create basic dictionary function more easily.  Try it below following these steps:\n",
      "\n",
      "-  the function should take a filename as input\n",
      "-  initialize an empty `defaultdict` `d`\n",
      "-  use our `read_file_lines` function to read the file into a list of lines\n",
      "-  loop over every line in the file\n",
      "-  use our `bcv_word_extract` function to extract the book-chapter-verse number and the appropriate word from that line\n",
      "-  append the word to the key from the `bcv_word_extract` function\n",
      "-  will finally return the dictionary that has been built"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "def build_verses(filename):\n",
      "    #insert your code here\n",
      "    d = defaultdict(list)\n",
      "    lines = read_file_lines(filename)\n",
      "    for line in lines:\n",
      "        bcv, word = bcv_word_extract(line)\n",
      "        d[bcv].append(word)\n",
      "    return d\n",
      "    \n",
      "\n",
      "Third_Jn_dict = build_verses('data/NT/Raw/85-3Jn-morphgnt.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Third_Jn_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<class 'list'>, {'250102': ['\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad', '\u03c0\u03b5\u03c1\u03af', '\u03c0\u03ac\u03bd\u03c4\u03c9\u03bd', '\u03b5\u1f54\u03c7\u03bf\u03bc\u03b1\u03b9', '\u03c3\u03b5', '\u03b5\u1f50\u03bf\u03b4\u03bf\u1fe6\u03c3\u03b8\u03b1\u03b9', '\u03ba\u03b1\u03af', '\u1f51\u03b3\u03b9\u03b1\u03af\u03bd\u03b5\u03b9\u03bd', '\u03ba\u03b1\u03b8\u03ce\u03c2', '\u03b5\u1f50\u03bf\u03b4\u03bf\u1fe6\u03c4\u03b1\u03b9', '\u03c3\u03bf\u03c5', '\u1f21', '\u03c8\u03c5\u03c7\u03ae'], '250113': ['\u03c0\u03bf\u03bb\u03bb\u03ac', '\u03b5\u1f36\u03c7\u03bf\u03bd', '\u03b3\u03c1\u03ac\u03c8\u03b1\u03b9', '\u03c3\u03bf\u03b9', '\u1f00\u03bb\u03bb\u03ac', '\u03bf\u1f50', '\u03b8\u03ad\u03bb\u03c9', '\u03b4\u03b9\u03ac', '\u03bc\u03ad\u03bb\u03b1\u03bd\u03bf\u03c2', '\u03ba\u03b1\u03af', '\u03ba\u03b1\u03bb\u03ac\u03bc\u03bf\u03c5', '\u03c3\u03bf\u03b9', '\u03b3\u03c1\u03ac\u03c6\u03b5\u03b9\u03bd'], '250109': ['\u1f14\u03b3\u03c1\u03b1\u03c8\u03b1', '\u03c4\u03b9', '\u03c4\u1fc7', '\u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u1fb3', '\u1f00\u03bb\u03bb\u03ac', '\u1f41', '\u03c6\u03b9\u03bb\u03bf\u03c0\u03c1\u03c9\u03c4\u03b5\u03cd\u03c9\u03bd', '\u03b1\u1f50\u03c4\u1ff6\u03bd', '\u0394\u03b9\u03bf\u03c4\u03c1\u03ad\u03c6\u03b7\u03c2', '\u03bf\u1f50', '\u1f10\u03c0\u03b9\u03b4\u03ad\u03c7\u03b5\u03c4\u03b1\u03b9', '\u1f21\u03bc\u1fb6\u03c2'], '250112': ['\u0394\u03b7\u03bc\u03b7\u03c4\u03c1\u03af\u1ff3', '\u03bc\u03b5\u03bc\u03b1\u03c1\u03c4\u03cd\u03c1\u03b7\u03c4\u03b1\u03b9', '\u1f51\u03c0\u03cc', '\u03c0\u03ac\u03bd\u03c4\u03c9\u03bd', '\u03ba\u03b1\u03af', '\u1f51\u03c0\u03cc', '\u03b1\u1f50\u03c4\u1fc6\u03c2', '\u03c4\u1fc6\u03c2', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u03b1\u03c2', '\u03ba\u03b1\u03af', '\u1f21\u03bc\u03b5\u1fd6\u03c2', '\u03b4\u03ad', '\u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03bf\u1fe6\u03bc\u03b5\u03bd', '\u03ba\u03b1\u03af', '\u03bf\u1f36\u03b4\u03b1\u03c2', '\u1f45\u03c4\u03b9', '\u1f21', '\u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03af\u03b1', '\u1f21\u03bc\u1ff6\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03ae\u03c2', '\u1f10\u03c3\u03c4\u03af(\u03bd)'], '250103': ['\u1f10\u03c7\u03ac\u03c1\u03b7\u03bd', '\u03b3\u03ac\u03c1', '\u03bb\u03af\u03b1\u03bd', '\u1f10\u03c1\u03c7\u03bf\u03bc\u03ad\u03bd\u03c9\u03bd', '\u1f00\u03b4\u03b5\u03bb\u03c6\u1ff6\u03bd', '\u03ba\u03b1\u03af', '\u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03bf\u03cd\u03bd\u03c4\u03c9\u03bd', '\u03c3\u03bf\u03c5', '\u03c4\u1fc7', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3', '\u03ba\u03b1\u03b8\u03ce\u03c2', '\u03c3\u03cd', '\u1f10\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3', '\u03c0\u03b5\u03c1\u03b9\u03c0\u03b1\u03c4\u03b5\u1fd6\u03c2'], '250105': ['\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad', '\u03c0\u03b9\u03c3\u03c4\u03cc\u03bd', '\u03c0\u03bf\u03b9\u03b5\u1fd6\u03c2', '\u1f45', '\u1f10\u03ac\u03bd', '\u1f10\u03c1\u03b3\u03ac\u03c3\u1fc3', '\u03b5\u1f30\u03c2', '\u03c4\u03bf\u03cd\u03c2', '\u1f00\u03b4\u03b5\u03bb\u03c6\u03bf\u03cd\u03c2', '\u03ba\u03b1\u03af', '\u03c4\u03bf\u1fe6\u03c4\u03bf', '\u03be\u03ad\u03bd\u03bf\u03c5\u03c2'], '250115': ['\u03b5\u1f30\u03c1\u03ae\u03bd\u03b7', '\u03c3\u03bf\u03b9', '\u1f00\u03c3\u03c0\u03ac\u03b6\u03bf\u03bd\u03c4\u03b1\u03b9', '\u03c3\u03b5', '\u03bf\u1f31', '\u03c6\u03af\u03bb\u03bf\u03b9', '\u1f00\u03c3\u03c0\u03ac\u03b6\u03bf\u03c5', '\u03c4\u03bf\u03cd\u03c2', '\u03c6\u03af\u03bb\u03bf\u03c5\u03c2', '\u03ba\u03b1\u03c4\u03ac', '\u1f44\u03bd\u03bf\u03bc\u03b1'], '250106': ['\u03bf\u1f35', '\u1f10\u03bc\u03b1\u03c1\u03c4\u03cd\u03c1\u03b7\u03c3\u03b1\u03bd', '\u03c3\u03bf\u03c5', '\u03c4\u1fc7', '\u1f00\u03b3\u03ac\u03c0\u1fc3', '\u1f10\u03bd\u03ce\u03c0\u03b9\u03bf\u03bd', '\u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1\u03c2', '\u03bf\u1f55\u03c2', '\u03ba\u03b1\u03bb\u1ff6\u03c2', '\u03c0\u03bf\u03b9\u03ae\u03c3\u03b5\u03b9\u03c2', '\u03c0\u03c1\u03bf\u03c0\u03ad\u03bc\u03c8\u03b1\u03c2', '\u1f00\u03be\u03af\u03c9\u03c2', '\u03c4\u03bf\u1fe6', '\u03b8\u03b5\u03bf\u1fe6'], '250104': ['\u03bc\u03b5\u03b9\u03b6\u03bf\u03c4\u03ad\u03c1\u03b1\u03bd', '\u03c4\u03bf\u03cd\u03c4\u03c9\u03bd', '\u03bf\u1f50', '\u1f14\u03c7\u03c9', '\u03c7\u03b1\u03c1\u03ac\u03bd', '\u1f35\u03bd\u03b1', '\u1f00\u03ba\u03bf\u03cd\u03c9', '\u03c4\u03ac', '\u1f10\u03bc\u03ac', '\u03c4\u03ad\u03ba\u03bd\u03b1', '\u1f10\u03bd', '\u03c4\u1fc7', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3', '\u03c0\u03b5\u03c1\u03b9\u03c0\u03b1\u03c4\u03bf\u1fe6\u03bd\u03c4\u03b1'], '250110': ['\u03b4\u03b9\u03ac', '\u03c4\u03bf\u1fe6\u03c4\u03bf', '\u1f10\u03ac\u03bd', '\u1f14\u03bb\u03b8\u03c9', '\u1f51\u03c0\u03bf\u03bc\u03bd\u03ae\u03c3\u03c9', '\u03b1\u1f50\u03c4\u03bf\u1fe6', '\u03c4\u03ac', '\u1f14\u03c1\u03b3\u03b1', '\u1f05', '\u03c0\u03bf\u03b9\u03b5\u1fd6', '\u03bb\u03cc\u03b3\u03bf\u03b9\u03c2', '\u03c0\u03bf\u03bd\u03b7\u03c1\u03bf\u1fd6\u03c2', '\u03c6\u03bb\u03c5\u03b1\u03c1\u1ff6\u03bd', '\u1f21\u03bc\u1fb6\u03c2', '\u03ba\u03b1\u03af', '\u03bc\u03ae', '\u1f00\u03c1\u03ba\u03bf\u03cd\u03bc\u03b5\u03bd\u03bf\u03c2', '\u1f10\u03c0\u03af', '\u03c4\u03bf\u03cd\u03c4\u03bf\u03b9\u03c2', '\u03bf\u1f54\u03c4\u03b5', '\u03b1\u1f50\u03c4\u03cc\u03c2', '\u1f10\u03c0\u03b9\u03b4\u03ad\u03c7\u03b5\u03c4\u03b1\u03b9', '\u03c4\u03bf\u03cd\u03c2', '\u1f00\u03b4\u03b5\u03bb\u03c6\u03bf\u03cd\u03c2', '\u03ba\u03b1\u03af', '\u03c4\u03bf\u03cd\u03c2', '\u03b2\u03bf\u03c5\u03bb\u03bf\u03bc\u03ad\u03bd\u03bf\u03c5\u03c2', '\u03ba\u03c9\u03bb\u03cd\u03b5\u03b9', '\u03ba\u03b1\u03af', '\u1f10\u03ba', '\u03c4\u1fc6\u03c2', '\u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1\u03c2', '\u1f10\u03ba\u03b2\u03ac\u03bb\u03bb\u03b5\u03b9'], '250107': ['\u1f51\u03c0\u03ad\u03c1', '\u03b3\u03ac\u03c1', '\u03c4\u03bf\u1fe6', '\u1f40\u03bd\u03cc\u03bc\u03b1\u03c4\u03bf\u03c2', '\u1f10\u03be\u1fc6\u03bb\u03b8\u03bf\u03bd', '\u03bc\u03b7\u03b4\u03ad\u03bd', '\u03bb\u03b1\u03bc\u03b2\u03ac\u03bd\u03bf\u03bd\u03c4\u03b5\u03c2', '\u1f00\u03c0\u03cc', '\u03c4\u1ff6\u03bd', '\u1f10\u03b8\u03bd\u03b9\u03ba\u1ff6\u03bd'], '250108': ['\u1f21\u03bc\u03b5\u1fd6\u03c2', '\u03bf\u1f56\u03bd', '\u1f40\u03c6\u03b5\u03af\u03bb\u03bf\u03bc\u03b5\u03bd', '\u1f51\u03c0\u03bf\u03bb\u03b1\u03bc\u03b2\u03ac\u03bd\u03b5\u03b9\u03bd', '\u03c4\u03bf\u03cd\u03c2', '\u03c4\u03bf\u03b9\u03bf\u03cd\u03c4\u03bf\u03c5\u03c2', '\u1f35\u03bd\u03b1', '\u03c3\u03c5\u03bd\u03b5\u03c1\u03b3\u03bf\u03af', '\u03b3\u03b9\u03bd\u03ce\u03bc\u03b5\u03b8\u03b1', '\u03c4\u1fc7', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3'], '250101': ['\u1f41', '\u03c0\u03c1\u03b5\u03c3\u03b2\u03cd\u03c4\u03b5\u03c1\u03bf\u03c2', '\u0393\u03b1\u0390\u1ff3', '\u03c4\u1ff7', '\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u1ff7', '\u1f45\u03bd', '\u1f10\u03b3\u03ce', '\u1f00\u03b3\u03b1\u03c0\u1ff6', '\u1f10\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3'], '250111': ['\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad', '\u03bc\u03ae', '\u03bc\u03b9\u03bc\u03bf\u1fe6', '\u03c4\u03cc', '\u03ba\u03b1\u03ba\u03cc\u03bd', '\u1f00\u03bb\u03bb\u03ac', '\u03c4\u03cc', '\u1f00\u03b3\u03b1\u03b8\u03cc\u03bd', '\u1f41', '\u1f00\u03b3\u03b1\u03b8\u03bf\u03c0\u03bf\u03b9\u1ff6\u03bd', '\u1f10\u03ba', '\u03c4\u03bf\u1fe6', '\u03b8\u03b5\u03bf\u1fe6', '\u1f10\u03c3\u03c4\u03af(\u03bd)', '\u1f41', '\u03ba\u03b1\u03ba\u03bf\u03c0\u03bf\u03b9\u1ff6\u03bd', '\u03bf\u1f50', '\u1f11\u03ce\u03c1\u03b1\u03ba\u03b5(\u03bd)', '\u03c4\u03cc\u03bd', '\u03b8\u03b5\u03cc\u03bd'], '250114': ['\u1f10\u03bb\u03c0\u03af\u03b6\u03c9', '\u03b4\u03ad', '\u03b5\u1f50\u03b8\u03ad\u03c9\u03c2', '\u03c3\u03b5', '\u1f30\u03b4\u03b5\u1fd6\u03bd', '\u03ba\u03b1\u03af', '\u03c3\u03c4\u03cc\u03bc\u03b1', '\u03c0\u03c1\u03cc\u03c2', '\u03c3\u03c4\u03cc\u03bc\u03b1', '\u03bb\u03b1\u03bb\u03ae\u03c3\u03bf\u03bc\u03b5\u03bd']})\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, so now we have a dictionary that has as its keys the `bcv` numbers for every verse in the book and as its values lists of the words in each of the verses.  Now the job is to split the keys into book, chapter, and verse and use this information to build our biblical dictionary that will be in the form that we saw above.\n",
      "\n",
      "First, let's build a function that takes as input the key as `str` from a dictionary and returns two objects: the chapter number (as `int`) and the verse number (as `int`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def chapter_verse(key):\n",
      "    #insert your code here\n",
      "    chapter = int(key[2:4])\n",
      "    verse = int(key[4:])\n",
      "    return chapter, verse\n",
      "    \n",
      "\n",
      "print(chapter_verse('250101') == (1, 1))\n",
      "print(chapter_verse('012025') == (20, 25))\n",
      "{1: {1: ['\u1f41', '\u03c0\u03c1\u03b5\u03c3\u03b2\u03cd\u03c4\u03b5\u03c1\u03bf\u03c2', '\u0393\u03b1\u0390\u1ff3', '\u03c4\u1ff7', '\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u1ff7', '\u1f45\u03bd', '\u1f10\u03b3\u03ce', '\u1f00\u03b3\u03b1\u03c0\u1ff6', '\u1f10\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3']}}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The final step in building the dictionary for each book is to put everything together into a function that takes a filename as input and returns a full dictionary for the biblical book represented by that file with each value in the form {chapter: {verse: [words]}}.\n",
      "\n",
      "N.B.: Use the `read_file_lines`, `build_verses`, and `chapter_verse` functions above.\n",
      "\n",
      "If you are getting a `KeyError` in your code, look closely at the error to see if you can figure out how to fix it.  Remember, you can't add a sub-key to a key if the key itself does not yet exist in your dictionary.  You might try to figure out how to use a `defaultdict` for this step as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_book_dict(filename):\n",
      "    #insert your code here\n",
      "    book_dict = {} # We need a dictionary\n",
      "    # This builds our first dictionary\n",
      "    # But the keys are not the ones that we want\n",
      "    # The dictionary looks like this: {'010101': []}\n",
      "    # But we want {1: {1: []}}\n",
      "    bcv_dict = build_verses(filename) \n",
      "    for key, value in bcv_dict.items(): # Get the key-value pairs\n",
      "        # Transform, e.g, '010101' to (1, 1)\n",
      "        chapter, verse = chapter_verse(key)\n",
      "        # Check to see if we have already added the chapter key\n",
      "        # If we have, add the verse sub-key and the value\n",
      "        if chapter in book_dict.keys():\n",
      "            book_dict[chapter][verse] = value\n",
      "        # If the chapter doesn't exist as a key then\n",
      "        # add the first {key: value} pair to the chapter key\n",
      "        else:\n",
      "            book_dict[chapter] = {verse: value}\n",
      "    return book_dict\n",
      "\n",
      "Third_Jn_final = build_book_dict('data/NT/Raw/85-3Jn-morphgnt.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(Third_Jn_final)\n",
      "print(Third_Jn_final[1][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{1: {1: ['\u1f41', '\u03c0\u03c1\u03b5\u03c3\u03b2\u03cd\u03c4\u03b5\u03c1\u03bf\u03c2', '\u0393\u03b1\u0390\u1ff3', '\u03c4\u1ff7', '\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u1ff7', '\u1f45\u03bd', '\u1f10\u03b3\u03ce', '\u1f00\u03b3\u03b1\u03c0\u1ff6', '\u1f10\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3'], 2: ['\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad', '\u03c0\u03b5\u03c1\u03af', '\u03c0\u03ac\u03bd\u03c4\u03c9\u03bd', '\u03b5\u1f54\u03c7\u03bf\u03bc\u03b1\u03b9', '\u03c3\u03b5', '\u03b5\u1f50\u03bf\u03b4\u03bf\u1fe6\u03c3\u03b8\u03b1\u03b9', '\u03ba\u03b1\u03af', '\u1f51\u03b3\u03b9\u03b1\u03af\u03bd\u03b5\u03b9\u03bd', '\u03ba\u03b1\u03b8\u03ce\u03c2', '\u03b5\u1f50\u03bf\u03b4\u03bf\u1fe6\u03c4\u03b1\u03b9', '\u03c3\u03bf\u03c5', '\u1f21', '\u03c8\u03c5\u03c7\u03ae'], 3: ['\u1f10\u03c7\u03ac\u03c1\u03b7\u03bd', '\u03b3\u03ac\u03c1', '\u03bb\u03af\u03b1\u03bd', '\u1f10\u03c1\u03c7\u03bf\u03bc\u03ad\u03bd\u03c9\u03bd', '\u1f00\u03b4\u03b5\u03bb\u03c6\u1ff6\u03bd', '\u03ba\u03b1\u03af', '\u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03bf\u03cd\u03bd\u03c4\u03c9\u03bd', '\u03c3\u03bf\u03c5', '\u03c4\u1fc7', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3', '\u03ba\u03b1\u03b8\u03ce\u03c2', '\u03c3\u03cd', '\u1f10\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3', '\u03c0\u03b5\u03c1\u03b9\u03c0\u03b1\u03c4\u03b5\u1fd6\u03c2'], 4: ['\u03bc\u03b5\u03b9\u03b6\u03bf\u03c4\u03ad\u03c1\u03b1\u03bd', '\u03c4\u03bf\u03cd\u03c4\u03c9\u03bd', '\u03bf\u1f50', '\u1f14\u03c7\u03c9', '\u03c7\u03b1\u03c1\u03ac\u03bd', '\u1f35\u03bd\u03b1', '\u1f00\u03ba\u03bf\u03cd\u03c9', '\u03c4\u03ac', '\u1f10\u03bc\u03ac', '\u03c4\u03ad\u03ba\u03bd\u03b1', '\u1f10\u03bd', '\u03c4\u1fc7', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3', '\u03c0\u03b5\u03c1\u03b9\u03c0\u03b1\u03c4\u03bf\u1fe6\u03bd\u03c4\u03b1'], 5: ['\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad', '\u03c0\u03b9\u03c3\u03c4\u03cc\u03bd', '\u03c0\u03bf\u03b9\u03b5\u1fd6\u03c2', '\u1f45', '\u1f10\u03ac\u03bd', '\u1f10\u03c1\u03b3\u03ac\u03c3\u1fc3', '\u03b5\u1f30\u03c2', '\u03c4\u03bf\u03cd\u03c2', '\u1f00\u03b4\u03b5\u03bb\u03c6\u03bf\u03cd\u03c2', '\u03ba\u03b1\u03af', '\u03c4\u03bf\u1fe6\u03c4\u03bf', '\u03be\u03ad\u03bd\u03bf\u03c5\u03c2'], 6: ['\u03bf\u1f35', '\u1f10\u03bc\u03b1\u03c1\u03c4\u03cd\u03c1\u03b7\u03c3\u03b1\u03bd', '\u03c3\u03bf\u03c5', '\u03c4\u1fc7', '\u1f00\u03b3\u03ac\u03c0\u1fc3', '\u1f10\u03bd\u03ce\u03c0\u03b9\u03bf\u03bd', '\u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1\u03c2', '\u03bf\u1f55\u03c2', '\u03ba\u03b1\u03bb\u1ff6\u03c2', '\u03c0\u03bf\u03b9\u03ae\u03c3\u03b5\u03b9\u03c2', '\u03c0\u03c1\u03bf\u03c0\u03ad\u03bc\u03c8\u03b1\u03c2', '\u1f00\u03be\u03af\u03c9\u03c2', '\u03c4\u03bf\u1fe6', '\u03b8\u03b5\u03bf\u1fe6'], 7: ['\u1f51\u03c0\u03ad\u03c1', '\u03b3\u03ac\u03c1', '\u03c4\u03bf\u1fe6', '\u1f40\u03bd\u03cc\u03bc\u03b1\u03c4\u03bf\u03c2', '\u1f10\u03be\u1fc6\u03bb\u03b8\u03bf\u03bd', '\u03bc\u03b7\u03b4\u03ad\u03bd', '\u03bb\u03b1\u03bc\u03b2\u03ac\u03bd\u03bf\u03bd\u03c4\u03b5\u03c2', '\u1f00\u03c0\u03cc', '\u03c4\u1ff6\u03bd', '\u1f10\u03b8\u03bd\u03b9\u03ba\u1ff6\u03bd'], 8: ['\u1f21\u03bc\u03b5\u1fd6\u03c2', '\u03bf\u1f56\u03bd', '\u1f40\u03c6\u03b5\u03af\u03bb\u03bf\u03bc\u03b5\u03bd', '\u1f51\u03c0\u03bf\u03bb\u03b1\u03bc\u03b2\u03ac\u03bd\u03b5\u03b9\u03bd', '\u03c4\u03bf\u03cd\u03c2', '\u03c4\u03bf\u03b9\u03bf\u03cd\u03c4\u03bf\u03c5\u03c2', '\u1f35\u03bd\u03b1', '\u03c3\u03c5\u03bd\u03b5\u03c1\u03b3\u03bf\u03af', '\u03b3\u03b9\u03bd\u03ce\u03bc\u03b5\u03b8\u03b1', '\u03c4\u1fc7', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3'], 9: ['\u1f14\u03b3\u03c1\u03b1\u03c8\u03b1', '\u03c4\u03b9', '\u03c4\u1fc7', '\u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u1fb3', '\u1f00\u03bb\u03bb\u03ac', '\u1f41', '\u03c6\u03b9\u03bb\u03bf\u03c0\u03c1\u03c9\u03c4\u03b5\u03cd\u03c9\u03bd', '\u03b1\u1f50\u03c4\u1ff6\u03bd', '\u0394\u03b9\u03bf\u03c4\u03c1\u03ad\u03c6\u03b7\u03c2', '\u03bf\u1f50', '\u1f10\u03c0\u03b9\u03b4\u03ad\u03c7\u03b5\u03c4\u03b1\u03b9', '\u1f21\u03bc\u1fb6\u03c2'], 10: ['\u03b4\u03b9\u03ac', '\u03c4\u03bf\u1fe6\u03c4\u03bf', '\u1f10\u03ac\u03bd', '\u1f14\u03bb\u03b8\u03c9', '\u1f51\u03c0\u03bf\u03bc\u03bd\u03ae\u03c3\u03c9', '\u03b1\u1f50\u03c4\u03bf\u1fe6', '\u03c4\u03ac', '\u1f14\u03c1\u03b3\u03b1', '\u1f05', '\u03c0\u03bf\u03b9\u03b5\u1fd6', '\u03bb\u03cc\u03b3\u03bf\u03b9\u03c2', '\u03c0\u03bf\u03bd\u03b7\u03c1\u03bf\u1fd6\u03c2', '\u03c6\u03bb\u03c5\u03b1\u03c1\u1ff6\u03bd', '\u1f21\u03bc\u1fb6\u03c2', '\u03ba\u03b1\u03af', '\u03bc\u03ae', '\u1f00\u03c1\u03ba\u03bf\u03cd\u03bc\u03b5\u03bd\u03bf\u03c2', '\u1f10\u03c0\u03af', '\u03c4\u03bf\u03cd\u03c4\u03bf\u03b9\u03c2', '\u03bf\u1f54\u03c4\u03b5', '\u03b1\u1f50\u03c4\u03cc\u03c2', '\u1f10\u03c0\u03b9\u03b4\u03ad\u03c7\u03b5\u03c4\u03b1\u03b9', '\u03c4\u03bf\u03cd\u03c2', '\u1f00\u03b4\u03b5\u03bb\u03c6\u03bf\u03cd\u03c2', '\u03ba\u03b1\u03af', '\u03c4\u03bf\u03cd\u03c2', '\u03b2\u03bf\u03c5\u03bb\u03bf\u03bc\u03ad\u03bd\u03bf\u03c5\u03c2', '\u03ba\u03c9\u03bb\u03cd\u03b5\u03b9', '\u03ba\u03b1\u03af', '\u1f10\u03ba', '\u03c4\u1fc6\u03c2', '\u1f10\u03ba\u03ba\u03bb\u03b7\u03c3\u03af\u03b1\u03c2', '\u1f10\u03ba\u03b2\u03ac\u03bb\u03bb\u03b5\u03b9'], 11: ['\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u03ad', '\u03bc\u03ae', '\u03bc\u03b9\u03bc\u03bf\u1fe6', '\u03c4\u03cc', '\u03ba\u03b1\u03ba\u03cc\u03bd', '\u1f00\u03bb\u03bb\u03ac', '\u03c4\u03cc', '\u1f00\u03b3\u03b1\u03b8\u03cc\u03bd', '\u1f41', '\u1f00\u03b3\u03b1\u03b8\u03bf\u03c0\u03bf\u03b9\u1ff6\u03bd', '\u1f10\u03ba', '\u03c4\u03bf\u1fe6', '\u03b8\u03b5\u03bf\u1fe6', '\u1f10\u03c3\u03c4\u03af(\u03bd)', '\u1f41', '\u03ba\u03b1\u03ba\u03bf\u03c0\u03bf\u03b9\u1ff6\u03bd', '\u03bf\u1f50', '\u1f11\u03ce\u03c1\u03b1\u03ba\u03b5(\u03bd)', '\u03c4\u03cc\u03bd', '\u03b8\u03b5\u03cc\u03bd'], 12: ['\u0394\u03b7\u03bc\u03b7\u03c4\u03c1\u03af\u1ff3', '\u03bc\u03b5\u03bc\u03b1\u03c1\u03c4\u03cd\u03c1\u03b7\u03c4\u03b1\u03b9', '\u1f51\u03c0\u03cc', '\u03c0\u03ac\u03bd\u03c4\u03c9\u03bd', '\u03ba\u03b1\u03af', '\u1f51\u03c0\u03cc', '\u03b1\u1f50\u03c4\u1fc6\u03c2', '\u03c4\u1fc6\u03c2', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u03b1\u03c2', '\u03ba\u03b1\u03af', '\u1f21\u03bc\u03b5\u1fd6\u03c2', '\u03b4\u03ad', '\u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03bf\u1fe6\u03bc\u03b5\u03bd', '\u03ba\u03b1\u03af', '\u03bf\u1f36\u03b4\u03b1\u03c2', '\u1f45\u03c4\u03b9', '\u1f21', '\u03bc\u03b1\u03c1\u03c4\u03c5\u03c1\u03af\u03b1', '\u1f21\u03bc\u1ff6\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03ae\u03c2', '\u1f10\u03c3\u03c4\u03af(\u03bd)'], 13: ['\u03c0\u03bf\u03bb\u03bb\u03ac', '\u03b5\u1f36\u03c7\u03bf\u03bd', '\u03b3\u03c1\u03ac\u03c8\u03b1\u03b9', '\u03c3\u03bf\u03b9', '\u1f00\u03bb\u03bb\u03ac', '\u03bf\u1f50', '\u03b8\u03ad\u03bb\u03c9', '\u03b4\u03b9\u03ac', '\u03bc\u03ad\u03bb\u03b1\u03bd\u03bf\u03c2', '\u03ba\u03b1\u03af', '\u03ba\u03b1\u03bb\u03ac\u03bc\u03bf\u03c5', '\u03c3\u03bf\u03b9', '\u03b3\u03c1\u03ac\u03c6\u03b5\u03b9\u03bd'], 14: ['\u1f10\u03bb\u03c0\u03af\u03b6\u03c9', '\u03b4\u03ad', '\u03b5\u1f50\u03b8\u03ad\u03c9\u03c2', '\u03c3\u03b5', '\u1f30\u03b4\u03b5\u1fd6\u03bd', '\u03ba\u03b1\u03af', '\u03c3\u03c4\u03cc\u03bc\u03b1', '\u03c0\u03c1\u03cc\u03c2', '\u03c3\u03c4\u03cc\u03bc\u03b1', '\u03bb\u03b1\u03bb\u03ae\u03c3\u03bf\u03bc\u03b5\u03bd'], 15: ['\u03b5\u1f30\u03c1\u03ae\u03bd\u03b7', '\u03c3\u03bf\u03b9', '\u1f00\u03c3\u03c0\u03ac\u03b6\u03bf\u03bd\u03c4\u03b1\u03b9', '\u03c3\u03b5', '\u03bf\u1f31', '\u03c6\u03af\u03bb\u03bf\u03b9', '\u1f00\u03c3\u03c0\u03ac\u03b6\u03bf\u03c5', '\u03c4\u03bf\u03cd\u03c2', '\u03c6\u03af\u03bb\u03bf\u03c5\u03c2', '\u03ba\u03b1\u03c4\u03ac', '\u1f44\u03bd\u03bf\u03bc\u03b1']}}\n",
        "['\u1f41', '\u03c0\u03c1\u03b5\u03c3\u03b2\u03cd\u03c4\u03b5\u03c1\u03bf\u03c2', '\u0393\u03b1\u0390\u1ff3', '\u03c4\u1ff7', '\u1f00\u03b3\u03b1\u03c0\u03b7\u03c4\u1ff7', '\u1f45\u03bd', '\u1f10\u03b3\u03ce', '\u1f00\u03b3\u03b1\u03c0\u1ff6', '\u1f10\u03bd', '\u1f00\u03bb\u03b7\u03b8\u03b5\u03af\u1fb3']\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now let's add our final wrapper function that will take as input a directory where our text files are located and will use the `list_textfiles` function to get a list of filenames from this directory, will call the `build_book_dict` function on every file, and then will assign the results of this to a new dictionary that has as its keys the book names.  The results will be a complete dictionary object with all the books, chapters, verses, and words from the New Testament."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testament_dict_builder(directory):\n",
      "    testament_dict = {}\n",
      "    #insert your code here\n",
      "    \n",
      "    return testament_dict\n",
      "\n",
      "NT_dict = testament_dict_builder('data/NT/Raw/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(NT_dict.keys())\n",
      "print(NT_dict['3Jn'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So now we have a great, really useful dictionary of the New Testament.  And if you wanted to, e.g., build a dictionary only of word lemmata, you could do this very easily just by changing the word form that you extract from each line.\n",
      "\n",
      "But right now, we want to figure out how to save this so that we don't have to rebuild it every time.  We learned above about saving text files, and we could do that here as well.  But then, if we wanted to reuse it in Python, we would have to figure out how to rebuild the dictionary from the text file.  And that seems like too much trouble.\n",
      "\n",
      "Luckily, Python (and many other programming languages) have a way of dealing with this.  It is called _serialization_ and it allows you to save Python objects as Python objects so that you could, e.g., save a dictionary as a dictionary or a list as a list, etc.  Python's serialization mechanism is called `pickle` and it is quite easy to use.  To save an object as a file, you use `pickle.dump(object, file)`.  To load a pickled object back into Python, you use `pickle.load(file)`.\n",
      "\n",
      "Let's take a look at a short example."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#First import the pickle library\n",
      "import pickle\n",
      "#Then create an object, here a dictionary.\n",
      "d = {'\u1f41': 'the', '\u03b8\u03b5\u03cc\u03c2': 'God'}\n",
      "#Then open a file object.\n",
      "pickle_file = open('pickled_dict.pickle', mode='wb')\n",
      "#Then dump our dictionary into the open file object\n",
      "pickle.dump(d, pickle_file)\n",
      "#And finally, as always, close the file object.\n",
      "pickle_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a closer look at this line in our code:\n",
      "\n",
      "    pickle_file = open('pickled_dict.pickle', mode='wb')\n",
      "    \n",
      "Notice that we opened the file in `mode='wb'`.  We should recognize the 'w': it means to open the file in write mode.  The 'b' means to open it as a bytes object instead of a text object.  This is the necessary mode for pickled files.  If you get an error that reads `TypeError: must be str, not bytes` while you are trying to pickle an object, you probably didn't open your file in bytes mode.  Check that first.\n",
      "\n",
      "And now, let's `load` the dictionary back into memory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#First, we need to open our file in 'rb' mode.\n",
      "pickled_file = open('pickled_dict.pickle', mode='rb')\n",
      "#Now, we load that file into a variable with a different name.\n",
      "d_1 = pickle.load(pickled_file)\n",
      "#Now, we can compare it to our original dictionary object.\n",
      "print(d==d_1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just for your own information, try taking the `mode='rb'` argument from the `open` function and take a look at the error you get.\n",
      "\n",
      "Now you know what the error will look like if you forget your `mode` argument.\n",
      "\n",
      "Now, write your own code below to `pickle.dump` our NT_dict object to some file that you will recognize.  Save the file in the `data/NT/Text/` folder so you'll know where to find it later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#insert your code here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exploratory data analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a first exploratory data analysis, we are going to compute for each biblical book how many chapters, verses, and words it contains. It is quite easy to count the number of chapters per book, since each book is represented by dictionary whose keys are the chapter numbers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chapters_per_book = {}\n",
      "for book, chapters in NT_dict.items():\n",
      "    chapters_per_book[book] = len(chapters)\n",
      "print(chapters_per_book['Lk'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the function `max` we can find out what the highest number of chapters is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max(chapters_per_book.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That can't be right!  Titus does not have the most chapters.  What happened?  Think about  it.  Can you figure it out?\n",
      "\n",
      "...think\n",
      "\n",
      "...think\n",
      "\n",
      "...think\n",
      "\n",
      "The `max` function goes through whatever iterable it is given, in this case the `items` of `chapters_per_book`, and, if each element is an iterable, as they are here, then it gives the max of the _first_ element of that iterable, in this case the book name.  And since the book names are strings, it returns the maximum value judged by alphabetical order, in this case 'Tit'.\n",
      "\n",
      "If we want the `max` to look at a different element of each iterable, we have to tell it to do this with the `key` argument.  Check out the code below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from operator import itemgetter\n",
      "max(chapters_per_book.items(), key=itemgetter(1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, but that `itemgetter` thing there still needs explanation!  `itemgetter` is a way to get a different element of an iterable than the first one.  What it does here is that it takes each element that the `max` function gives it (in our case each of the `chapters_per_book.items()` key-value tuples) and returns the index 1 element of that element, i.e., the second element of each element.  As we can see, this now returns the value we were expecting.  \n",
      "\n",
      "We can also use the same `key` argument with the `sorted` function to get a sorted list of the books by number of chapters:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(chapters_per_book.items(), key=itemgetter(1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, can you figure out how to write a similar piece of code as above to discover the number of verses per book?\n",
      "\n",
      "__Hint:__ You need to go one level deeper into the NT_dict.  And make sure to count the number of verses in every chapter of every book"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Insert your code here.\n",
      "verses_per_book = {}\n",
      "\n",
      "\n",
      "print(verses_per_book['Ro'] == 430)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `sum` takes a list of numbers as input and returns the sum:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(sum([1, 3, 3, 4]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use this function to compute the _average_ number of verses per book. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# insert your code here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given our data structure of a dictionary with three levels of keys and finally a list of words as the values for the third level, it is a little trickier to count for each book how many words it contains. One possible way is the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words_per_book = {}\n",
      "for book, chapters in NT_dict.items():\n",
      "    n_words = 0\n",
      "    for chapter, verses in chapters.items():\n",
      "        for verse, words in verses.items():\n",
      "            n_words += len(words)\n",
      "    words_per_book[book] = n_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(words_per_book['Ro'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make sure you really understand these lines of code as you will need them in the next quiz. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The New Testament was written to be heard by groups of early Christians, not to be read silently by individual believers.  Whether the letters of Paul or the Gospel of Mark, the biblical books were read aloud in house churches and larger gatherings.  So how long would one have to sit if one were, for instance, a Christian in Rome hearing Paul's letter to the Romans read for the first time.\n",
      "\n",
      "I am not aware of any exact numbers about how many words people speak per minute. Averages seem to fluctuate between 100 and 200 words per minute. Narrators are advised to use approximately 150 words per minute in audiobooks. I suspect that this number is a little lower for live reading of a document one has never seen and assume it lies around 130 words per minute (including pauses). Using this information, we can compute the time it takes to read a particular book as follows:\n",
      "\n",
      "$$\\textrm{reading time}(\\textrm{text}) = \\frac{\\textrm{number of words in text}}{\\textrm{number of words per minute}}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1)** Write a function called `reading_time` that takes as input the name of a biblical book and the number of words in that book. Given a speed of 130 words per minute, compute how long it takes to read that text and return a dictionary with the name of the book as the key and the number of minutes it takes to read the book as the value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reading_time(book, n_words):\n",
      "    # insert your code here\n",
      "    \n",
      "\n",
      "# these tests should return True if your code is correct\n",
      "print(reading_time(\"Mt\", 130) == {\"Mt\": 1.0})\n",
      "print(reading_time(\"Ro\", 390) == {\"Ro\": 3.0})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2)** Compute the reading_time for each book in the NT. Assign the result to the dictionary `reading_time_per_book`.\n",
      "\n",
      "__Hint:__ You can add the key value pairs from one dictionary object to another dictionary thus:\n",
      "\n",
      "    dict1.update(dict2)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reading_time_per_book = {}\n",
      "# insert your code here\n",
      "\n",
      "print(reading_time_per_book['Ro'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3**) Compute the average, minimum and maximum book reading time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# insert your code here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Visualizing general statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have computed a range of general statistics for our corpus, it would be nice to visualize them. Python's plotting library *matplotlib* (see [here](http://matplotlib.org)) allows us to produce all kinds of graphs. We could for example, plot for each book, how many verses it contains:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "plt.plot(list(verses_per_book.values())) #the data for the plot\n",
      "plt.xticks(range(len(verses_per_book)), list(verses_per_book.keys()), rotation = 85) #ticks, labels, and rotation on x-axis\n",
      "plt.show() #this will show the plot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1)** Can you do the same for `words_per_book`?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# insert your code here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2)** And can you do the same for `reading_time_per_book`?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# insert your code here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3)** In this final exercise we will put everything together what we have learnt so far. We want you to write a function `verses_with` that takes as input a word and the dictionary you want to search and returns the verses in the NT in which a given word occurs. We are not worried about the number of occurrences, only whether it occurs.  The result for each word should be a list with each element being another list that has three elements, the book name, chapter, and verse in which the word occurs, e.g., `[['Mt', 1, 1], ['Mt', 1, 2]]`.  Use that function to find all occurences of the name \u1f38\u03b7\u03c3\u03bf\u1fe6\u03c2 and store the corresponding results in the variable `verses_with_Jesus`. Do the same thing for \u03b8\u03b5\u03cc\u03c2. Store the result in `verses_with_God`. Finally, find all occurences of \u03c0\u03bd\u03b5\u1fe6\u03bc\u03b1 and store the indexes in `verses_with_Spirit`. Tip: (1) remember that we built our NT_dict using inflected forms of the words (2) remember that indexes start at 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def verses_with(word, d):\n",
      "    #insert your code here\n",
      "    \n",
      "\n",
      "verses_with_Jesus = verses_with(\"\u1f38\u03b7\u03c3\u03bf\u1fe6\u03c2\", NT_dict)\n",
      "verses_with_God = verses_with(\"\u03b8\u03b5\u03cc\u03c2\", NT_dict)\n",
      "verses_with_Spirit = verses_with(\"\u03c0\u03bd\u03b5\u1fe6\u03bc\u03b1\", NT_dict)\n",
      "print(verses_with_Jesus[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, in order to graph our results, we first need a list of the numerical positions of all of the verses in the NT so that we can assign actual location numbers to all of the occurrences for each word.  So, first, write some code below that will extract all of the book names, chapter numbers, and verse numbers for every verse in the NT.  It will be quite similar to the function you wrote above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NT_verses = []\n",
      "#insert your code here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, in order to sort these verses according to the order of their occurrence in the NT, we do the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NT_book_order = ['Mt', 'Mk', 'Lk', 'Jn', 'Ac', 'Ro', '1Co', '2Co', 'Ga', 'Eph', 'Php', \n",
      "                 'Col', '1Th', '2Th', '1Ti', '2Ti', 'Tit', 'Phm', 'Heb', 'Jas', '1Pe', \n",
      "                 '2Pe', '1Jn', '2Jn', '3Jn', 'Jud', 'Re']\n",
      "sorted_verses = sorted(NT_verses, key=lambda x: NT_book_order.index(x[0]))\n",
      "print(sorted_verses[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, we have seen the `key` argument on the `sorted` function, but what is that `lambda` thing?  `lambda` is essentially Python's way of building mini functions.  It essentially says, \"For a value we shall call _x_, do the following thing with it.\"  In this case, what we do is use the value of _x_ to look up a value in the list `NT_book_order`.  You need to remember that `sorted` goes through every member of the list `NT_verses` and passes the value of that member to the `key` argument.  `lambda` picks up the value that is passed to `key` as _x_ and, in this case, uses the first member of the list _x_ to figure out how it should order the members of `NT_verses`.  \n",
      "\n",
      "If `lambda` statements are still a mystery to you, don't worry.  They are mysterious things.  But the more you experiment with them and use them, the more familiar with them you will become.  Consider this your introduction to `lambda` statements!\n",
      "\n",
      "Now, the last step is to produce a list of the numerical positions of every occurrence of each of our words.  To do this, you should write a function below that takes as input a list of the book, chapter, and verses for the occurrence of a word and another list with the books, chapters, and verses for the whole NT and will return a list that has the relative positions for that word in the whole NT represented as a float."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def positions_of(word_list, NT_list):\n",
      "    #insert your code here\n",
      "    \n",
      "\n",
      "positions_of_Jesus = positions_of(verses_with_Jesus, sorted_verses)\n",
      "positions_of_God = positions_of(verses_with_God, sorted_verses)\n",
      "positions_of_Spirit = positions_of(verses_with_Spirit, sorted_verses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If everything went well, the following lines of code should produce a nice dispersion plot of all verse occurences of \u1f38\u03b7\u03c3\u03bf\u1fe6\u03c2, \u03b8\u03b5\u03cc\u03c2, \u03c0\u03bd\u03b5\u1fe6\u03bc\u03b1 in the NT."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "book_tick_locs = []\n",
      "for book in NT_book_order:\n",
      "    book_tick_locs.append(float(sorted_verses.index([book, 1, 1])))\n",
      "plt.figure(figsize=(20, 8))\n",
      "words = [u\"\u1f38\u03b7\u03c3\u03bf\u1fe6\u03c2\", u\"\u03b8\u03b5\u03cc\u03c2\", u\"\u03c0\u03bd\u03b5\u1fe6\u03bc\u03b1\"]\n",
      "plt.plot(positions_of_Jesus, [1]*len(positions_of_Jesus), \"|\", markersize=100)\n",
      "plt.plot(positions_of_God, [2]*len(positions_of_God), \"|\", markersize=100)\n",
      "plt.plot(positions_of_Spirit, [0]*len(positions_of_Spirit), \"|\", markersize=100)\n",
      "plt.yticks(range(len(words)), words)\n",
      "plt.ylim(-1, 3)\n",
      "plt.xticks(book_tick_locs, NT_book_order, rotation = 85)\n",
      "plt.xlim(0, len(sorted_verses))\n",
      "plt.axes().grid(axis='x')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How do the results look?  Are they what you expected?  Why or why not?  If they are not, how could you change your input to give you results that are more like what you would expect?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ignore the following, it's just here to make the page pretty:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p><small><a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Python Programming for the Humanities</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://fbkarsdorp.github.io/python-course\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">http://fbkarsdorp.github.io/python-course</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>. Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/fbkarsdorp/python-course\" rel=\"dct:source\">https://github.com/fbkarsdorp/python-course</a>.</small></p>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}